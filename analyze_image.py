import argparse
import base64
import json
import mimetypes
import os
import sys
from urllib.parse import urlparse

from PIL import Image
import numpy as np
from dotenv import load_dotenv
from bfl_finetune import finetune_inference, get_inference
import time
import requests
from io import BytesIO
from openai import OpenAI


# =========================
# OpenAI SDK
# =========================
try:
    from openai import OpenAI
except ImportError:
    print("`pip install openai` ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

HUMAN_LABELS = {"girl","boy","woman","man","person","child","character"}

def _object_phrase(o):
    label = _clean_label(o.get("label"))
    if not label:
        return None
    attr = o.get("attributes", {}) or {}
    other = (attr.get("other") or "").lower()
    material = (attr.get("material") or "").lower()
    pattern  = (attr.get("pattern")  or "").lower()
    color_adj = None
    if isinstance(o.get("dominant_color_hex"), str):
        color_adj = _nearest_color_name(o["dominant_color_hex"])

    # ì‚¬ëŒ: ìƒ‰ì€ 'ì‚¬ëŒ'ì´ ì•„ë‹ˆë¼ 'ì˜ìƒ'ì— ë¶™ì„, fabric ìƒëµ
    if label in HUMAN_LABELS:
        phrase = f"a {label}"
        if color_adj:
            phrase += f" wearing {color_adj} clothes"
        # ë¨¸ë¦¬ í‘œí˜„ë§Œ ì„ íƒì ìœ¼ë¡œ
        hair = None
        low = other
        if "curly" in low: hair = "curly hair"
        elif "straight" in low: hair = "straight hair"
        if hair:
            phrase += f" with {hair}"
        return phrase

    # ë‚˜ë¬´: leafy + ìƒ‰ + tree, wood ìƒëµ
    if label == "tree":
        leafy = ("leafy" in other) or ("leafy" in pattern)
        base_color = color_adj or "brown"
        prefix = "leafy " if leafy else ""
        return f"a {prefix}{base_color} tree".strip()

    # ì¼ë°˜ ê°ì²´(ì˜ˆ: dog ë“±)
    phrase = f"a {color_adj} {label}" if color_adj else f"a {label}"
    extras = []
    if material == "fur" or "fur" in other:
        extras.append("fur")
    # ì¹œê·¼/í‘œì •ë¥˜
    if "friendly" in other:
        extras.append("friendly expression")
    elif other and other not in ("solid",):
        extras.append(other)
    if extras:
        phrase += " with " + " and ".join(extras)
    return phrase

# =========================
# íŒŒì¼/ê²½ë¡œ ìœ í‹¸
# =========================
IMG_EXTS = {".png", ".jpg", ".jpeg", ".webp", ".bmp", ".gif"}

def ensure_dir(p: str):
    os.makedirs(p, exist_ok=True)

def save_json(obj: dict, path: str):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)

def list_reference_images(ref_dir: str):
    out = []
    if not os.path.isdir(ref_dir):
        return out
    with os.scandir(ref_dir) as it:
        for e in it:
            if not e.is_file():
                continue
            _, ext = os.path.splitext(e.name.lower())
            if ext in IMG_EXTS:
                try:
                    stat = e.stat()
                    out.append((e.path, e.name, stat.st_mtime))
                except Exception:
                    continue
    return out

def sort_images(items, mode="newest"):
    if mode == "newest":
        return sorted(items, key=lambda x: x[2], reverse=True)
    if mode == "oldest":
        return sorted(items, key=lambda x: x[2])
    return sorted(items, key=lambda x: x[1].lower())

# =========================
# ì´ë¯¸ì§€ ë¡œë“œ/ì¸ì½”ë”©
# =========================
def load_image_as_data_url(image_path_or_url: str) -> str:
    parsed = urlparse(image_path_or_url)
    if parsed.scheme in ("http", "https"):
        return image_path_or_url
    if not os.path.exists(image_path_or_url):
        raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path_or_url}")
    mime, _ = mimetypes.guess_type(image_path_or_url)
    if mime is None:
        mime = "image/jpeg"
    with open(image_path_or_url, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("utf-8")
    return f"data:{mime};base64,{b64}"

def approx_dominant_hex(image_path_or_url: str) -> str | None:
    parsed = urlparse(image_path_or_url)
    if parsed.scheme in ("http", "https"):
        return None
    try:
        img = Image.open(image_path_or_url).convert("RGB")
        img_small = img.resize((64, 64))
        arr = np.array(img_small).reshape(-1, 3)
        mean = arr.mean(axis=0).astype(int)
        return "#{:02x}{:02x}{:02x}".format(mean[0], mean[1], mean[2])
    except Exception:
        return None

# =========================
# ë¹„ì „ ë¶„ì„ í”„ë¡¬í”„íŠ¸(ëª¨ë¸ ì§€ì¹¨)
# =========================
SYSTEM_PROMPT = """You are a precise vision-to-JSON extractor.
Only return valid JSON that strictly matches the provided schema.
If unsure, estimate and reflect uncertainty in descriptions (not the schema).
All bounding boxes are normalized floats in [0,1] with top-left origin.
"""

JSON_SCHEMA_TEXT = """
Return a JSON object like this (keys must match exactly):

{
  "image_info": {
    "width_px": null,
    "height_px": null,
    "inferred_scene": "",
    "notes": ""
  },
  "style": {
    "genre": "",
    "rendering": "",
    "line_style": "",
    "color_palette": "",
    "lighting": "",
    "tone_mood": "",
    "shading": "",
    "texture": "",
    "composition": "",
    "references": ""
  },
  "style_tags": ["tag1","tag2","tag3"],
  "objects": [
    {
      "id": "obj_1",
      "label": "",
      "confidence": 0.0,
      "bbox_norm": { "x": 0.0, "y": 0.0, "w": 0.0, "h": 0.0 },
      "dominant_color_hex": "#000000",
      "attributes": {
        "material": "",
        "pattern": "",
        "shape": "",
        "size": "",
        "other": ""
      }
    }
  ]
}
Rules:
- style_tags: 5~10 short, model-friendly tags; lowercase; hyphen for multi-word.
- color_palette: brief overall description, not hex list.
"""

USER_INSTRUCTIONS = """Extract:
1) Objects with normalized bounding boxes, dominant color hex, and attributes.
2) Overall image style (genre, rendering, line style, color palette, lighting, tone/mood, shading, texture, composition, references).
3) 5~10 concise style tags (e.g., ["flat-2d","cartoon","soft-lighting","warm-palette","bold-outline"]).
Return strictly valid JSON matching the schema.
"""

# =========================
# OpenAI í˜¸ì¶œ
# =========================
def call_gpt_vision(image_ref: str, api_key: str, model: str = "gpt-4o-mini") -> dict:
    client = OpenAI(api_key=api_key)
    completion = client.chat.completions.create(
        model=model,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": JSON_SCHEMA_TEXT},
                    {"type": "text", "text": USER_INSTRUCTIONS},
                    {"type": "image_url", "image_url": {"url": image_ref}},
                ],
            },
        ],
        temperature=0.1,
    )
    text = completion.choices[0].message.content
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        text_fixed = text.strip().split("```")[-1]
        text_fixed = text_fixed.replace("json\n", "").replace("json", "")
        return json.loads(text_fixed)

# =========================
# ìœ„ì¹˜/ìƒ‰ìƒ ìœ í‹¸
# =========================
def _bbox_center(b):
    cx = float(b.get("x", 0.0)) + float(b.get("w", 0.0)) / 2.0
    cy = float(b.get("y", 0.0)) + float(b.get("h", 0.0)) / 2.0
    return cx, cy

def _region_phrase(cx, cy, tol=0.1):
    if cx < 0.5 - tol: horiz = "left"
    elif cx > 0.5 + tol: horiz = "right"
    else: horiz = "center"
    if cy < 0.5 - tol: vert = "upper"
    elif cy > 0.5 + tol: vert = "lower"
    else: vert = "middle"
    if horiz == "center" and vert == "middle":
        return "the center"
    if vert in ("upper","lower"):
        return f"the {vert} {horiz}"
    return f"the {horiz}"

def _relative_phrase(a_label, a_bbox, b_label, b_bbox, near_thresh=0.12, overlap_thresh=0.25):
    ax, ay = _bbox_center(a_bbox); bx, by = _bbox_center(b_bbox)
    dx, dy = ax - bx, ay - by
    dist = (dx**2 + dy**2) ** 0.5
    ax0, ax1 = a_bbox["x"], a_bbox["x"] + a_bbox["w"]
    bx0, bx1 = b_bbox["x"], b_bbox["x"] + b_bbox["w"]
    overlap = max(0.0, min(ax1, bx1) - max(ax0, bx0))
    union = max(ax1, bx1) - min(ax0, bx0)
    overlap_ratio = (overlap / union) if union > 0 else 0.0
    if dx < -0.08:
        return f"The {a_label} is to the left of the {b_label}."
    if dx >  0.08:
        return f"The {a_label} is to the right of the {b_label}."
    if overlap_ratio >= overlap_thresh:
        if dy > 0.08:
            return f"The {a_label} is below the {b_label}."
        if dy < -0.08:
            return f"The {a_label} is above the {b_label}."
    if dist <= near_thresh:
        return f"The {a_label} is near the {b_label}."
    return None

def _clean_label(label: str) -> str:
    return (label or "").lower().strip()

def _hex_to_rgb(hexstr: str):
    hexstr = hexstr.lstrip("#")
    if len(hexstr) != 6:
        return (128,128,128)
    return tuple(int(hexstr[i:i+2], 16) for i in (0,2,4))

_BASIC_COLORS = {
    "white": (255,255,255), "black": (0,0,0), "red": (255,0,0),
    "green": (0,170,0), "blue": (0,102,255), "yellow": (255,212,0),
    "gray": (136,136,136), "brown": (139,69,19), "pink": (255,192,203),
    "purple": (128,0,128), "orange": (255,165,0), "beige": (245,222,179),
    "silver": (192,192,192), "gold": (212,175,55), "cyan": (0,255,255),
    "magenta": (255,0,255),
}

def _nearest_color_name(hexstr: str) -> str | None:
    try:
        r,g,b = _hex_to_rgb(hexstr)
    except Exception:
        return None
    best, bestd = None, 1e9
    for name,(R,G,B) in _BASIC_COLORS.items():
        d = (r-R)**2 + (g-G)**2 + (b-B)**2
        if d < bestd:
            best, bestd = name, d
    return best

# =========================
# í”„ë¡¬í”„íŠ¸ ìƒì„±(EN â†’ KO)
# =========================
def build_english_prompt(analysis: dict) -> str:
    info = analysis.get("image_info", {}) or {}
    style = analysis.get("style", {}) or {}
    objs = analysis.get("objects", []) or []

    scene = (info.get("inferred_scene") or "").strip()
    notes = (info.get("notes") or "").strip()

    lines = []
    if scene:
        lines.append(scene.rstrip(".") + ".")

    # ê°ì²´(ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸êµ¬ë¡œ í•©ì„±)
    phrases = []
    for o in objs:
        phrase = _object_phrase(o)
        if phrase:
            phrases.append(phrase)


        if phrases:
            if len(phrases) == 1:
                lines.append(f"The scene includes {phrases[0]}.")
            elif len(phrases) == 2:
                lines.append(f"The scene includes {phrases[0]} and {phrases[1]}.")
            else:
                lines.append(f"The scene includes {', '.join(phrases[:-1])}, and {phrases[-1]}.")

    # ì ˆëŒ€ ìœ„ì¹˜
    pos_sents = []
    for o in objs:
        label = _clean_label(o.get("label"))
        bbox = (o.get("bbox_norm") or {})
        if not label or not {"x","y","w","h"} <= set(bbox.keys()):
            continue
        cx, cy = _bbox_center(bbox)
        region = _region_phrase(cx, cy, tol=0.1)
        verb = "stands" if label in ("girl","boy","person","man","woman","character","child") else "is"
        pos_sents.append(f"The {label} {verb} in {region}.")

    # ìƒëŒ€ ìœ„ì¹˜(ìƒìœ„ 3ê°œê¹Œì§€ë§Œ)
    objs_for_rel = objs[:3]
    for i in range(len(objs_for_rel)):
        for j in range(i+1, len(objs_for_rel)):
            a = objs_for_rel[i]; b = objs_for_rel[j]
            a_label = _clean_label(a.get("label")); b_label = _clean_label(b.get("label"))
            a_bbox = a.get("bbox_norm") or {}; b_bbox = b.get("bbox_norm") or {}
            if not a_label or not b_label: continue
            if not ({"x","y","w","h"} <= set(a_bbox.keys()) and {"x","y","w","h"} <= set(b_bbox.keys())):
                continue
            rel = _relative_phrase(a_label, a_bbox, b_label, b_bbox)
            if rel: pos_sents.append(rel)

    if pos_sents:
        seen, uniq = set(), []
        for s in pos_sents:
            if s not in seen:
                uniq.append(s); seen.add(s)
        lines.append(" ".join(uniq))

    # ìŠ¤íƒ€ì¼/í†¤
    style_bits = []
    for key in ["genre","rendering","line_style","color_palette","lighting","tone_mood","shading","texture"]:
        val = (style.get(key) or "").strip()
        if val:
            style_bits.append(val)
    # 'illustration' ë‹¨ì–´ ì¤‘ë³µ ì œê±°
    filtered = [b for b in style_bits if b.lower() not in {"illustration","an illustration","a illustration"}]
    if filtered:
        # ê´€ì‚¬ ì˜¤ë¥˜ ë°©ì§€: ê·¸ëƒ¥ ëª…ì‚¬êµ¬ ë‚˜ì—´
        lines.append("The illustration is rendered in " + ", ".join(filtered) + " style.")

    if style.get("composition"):
        lines.append(f"The composition is {style['composition']}.")
    if notes:
        lines.append(notes.rstrip(".") + ".")
    lines.append("Child-friendly picture-book illustration, flat 2D digital illustration, high quality.")

    out = " ".join(" ".join(l.split()) for l in lines).strip()
    return out

# def english_to_korean_prompt(en_prompt: str, api_key: str, model: str = "gpt-4o-mini") -> str:
#     client = OpenAI(api_key=api_key)
#     sys_msg = (
#         "You are a professional Korean copywriter for children's picture-book prompts. "
#         "Rewrite the given English prompt into fluent Korean natural sentences for an image generation model. "
#         "Keep spatial relations and composition details, and DO NOT omit any concrete nouns. "
#         "Translate spatial words explicitly: left, right, upper, lower, center, middle. "
#         "Include the phrase 'í”Œë« 2D ë””ì§€í„¸ ì¼ëŸ¬ìŠ¤íŠ¸' verbatim. "
#         "Do NOT use colons, bullets, or list-like structures. 2-4 sentences. No code blocks."
#     )
#     user_msg = f"English prompt:\n{en_prompt}\n\nRewrite in Korean as natural sentences."
#     resp = client.chat.completions.create(
#         model=model,
#         temperature=0.2,
#         messages=[
#             {"role": "system", "content": sys_msg},
#             {"role": "user", "content": user_msg},
#         ],
#     )
#     ko = resp.choices[0].message.content.strip()
#     return ko.replace("```", "").strip()
from openai import OpenAI

def english_to_korean_prompt_strict(en_prompt: str, api_key: str, model: str = "gpt-4o-mini") -> str:
    """
    ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ 'ì¶©ì‹¤í•˜ê²Œ' ë²ˆì—­:
    - ëª¨ë“  ì‚¬ì‹¤(ì£¼ì²´, ìƒ‰ìƒ, ì¬ì§ˆ, ìœ„ì¹˜/ê´€ê³„, ìŠ¤íƒ€ì¼/ë¬´ë“œ, êµ¬ì„±)ì„ 1ê°œë„ ë¹ ëœ¨ë¦¬ì§€ ì•ŠìŒ
    - ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ 2~4ê°œ, ì½œë¡ /ë¦¬ìŠ¤íŠ¸/ì½”ë“œë¸”ë¡ ê¸ˆì§€
    - í•µì‹¬ ìš©ì–´ ê³ ì • ë²ˆì—­(ì˜ˆ: upper left, bold outlines, flat 2D digital illustration ë“±)
    """
    client = OpenAI(api_key=api_key)
    sys_msg = (
        "You are a FAITHFUL translator. Translate the English prompt into fluent Korean sentences "
        "(2â€“4 sentences). DO NOT add or omit any factual detail: subjects, colors (e.g., blue), "
        "materials, absolute/relative positions, style descriptors, mood, and composition. "
        "No lists, no colons, no quotes, no code blocks. Keep everything factual."
    )
    # í•µì‹¬ ìš©ì–´ ê³ ì • ë§¤í•‘ì„ íŒíŠ¸ë¡œ ì œê³µ
    mapping = """
Use these fixed Korean mappings:
- upper left â†’ ì™¼ìª½ ìƒë‹¨
- lower left â†’ ì™¼ìª½ í•˜ë‹¨
- upper right â†’ ì˜¤ë¥¸ìª½ ìƒë‹¨
- lower right â†’ ì˜¤ë¥¸ìª½ í•˜ë‹¨
- to the right of â†’ ì˜¤ë¥¸ìª½ì—
- to the left of â†’ ì™¼ìª½ì—
- center / centered â†’ ì¤‘ì•™ / ì¤‘ì•™ì—
- flat, 2D digital illustration â†’ í”Œë« 2D ë””ì§€í„¸ ì¼ëŸ¬ìŠ¤íŠ¸
- bold outlines â†’ êµµì€ ìœ¤ê³½ì„ 
- soft, muted colors â†’ ë¶€ë“œëŸ½ê³  ì°¨ë¶„í•œ ìƒ‰ì¡°
- playful demeanor â†’ ì¥ë‚œìŠ¤ëŸ¬ìš´/ìœ ì¾Œí•œ ë¶„ìœ„ê¸°
"""
    resp = client.chat.completions.create(
        model=model,
        temperature=0.0,  # âœ… ì°½ì˜ì„± ë”: ëˆ„ë½/ë³€í˜• ë°©ì§€
        messages=[
            {"role": "system", "content": sys_msg},
            {"role": "user", "content": mapping.strip() + "\n\n" + en_prompt},
        ],
    )
    return resp.choices[0].message.content.strip().replace("```", "").strip()

# =========================
# í¸ì§‘(í•œêµ­ì–´ â†’ ì˜ì–´ edits â†’ ì ìš© â†’ ì˜ì–´ ì •ê·œí™”)
# =========================
_EDIT_SCHEMA = """
Return JSON with the exact shape:
{
  "edits": [
    {
      "object_match": { "id": "", "label": "" },  // at least one key present
      "set": {
        "label": "",
        "dominant_color_hex": "#ffffff",
        "bbox_norm": { "x": 0.0, "y": 0.0, "w": 0.0, "h": 0.0 },
        "attributes": {
          "material": "",
          "pattern": "",
          "shape": "",
          "size": "",
          "other": ""
        }
      },
      "why": ""
    }
  ]
}
Rules:
- All values inside `set` MUST be in ENGLISH only (concise nouns/adjectives).
- Only include fields you intend to change in the `set` object.
- For colors, always set a valid 7-char HEX in `dominant_color_hex`.
- Use existing labels/ids from the provided JSON when possible.
- If the instruction is ambiguous, choose the most likely single target.
"""

# í•œêµ­ì–´ ìƒ‰ìƒ â†’ HEX íŒíŠ¸(ëª¨ë¸ ê°€ì´ë“œìš©)
_COLOR_HINT = """
Korean color words to HEX mapping (use when user instruction mentions colors):
í°ìƒ‰/í•˜ì–€ìƒ‰:white=#FFFFFF, ê²€ì •/ê²€ì€ìƒ‰:black=#000000, ë¹¨ê°•/ë¹¨ê°„ìƒ‰:red=#FF0000, íŒŒë‘/íŒŒë€ìƒ‰:blue=#0066FF,
ì´ˆë¡/ì´ˆë¡ìƒ‰:green=#00AA00, ë…¸ë‘/ë…¸ë€ìƒ‰:yellow=#FFD400, ì£¼í™©/ì£¼í™©ìƒ‰:orange=#FFA500, ê°ˆìƒ‰:brown=#8B4513,
íšŒìƒ‰:gray=#888888, ë¶„í™/ë¶„í™ìƒ‰:pink=#FFC0CB, ë³´ë¼/ë³´ë¼ìƒ‰:purple=#800080, ë² ì´ì§€:beige=#F5DEB3,
ì€ìƒ‰:silver=#C0C0C0, ê¸ˆìƒ‰:gold=#D4AF37, ì²­ë¡:cyan=#00FFFF, ìí™:magenta=#FF00FF
"""

def propose_edits_via_gpt(current_json: dict, user_instruction_ko: str, api_key: str, model: str = "gpt-4o-mini") -> dict:
    client = OpenAI(api_key=api_key)
    sys_msg = (
        "You convert Korean user edit requests into structured JSON edits to modify an existing analysis JSON. "
        "All output string values inside `set` must be ENGLISH ONLY. Be minimal and precise. Always return valid JSON."
    )
    payload = json.dumps(current_json, ensure_ascii=False)
    user_msg = (
        f"Current analysis JSON:\n{payload}\n\n"
        f"User edit request (Korean): {user_instruction_ko}\n\n"
        f"Use this color mapping when needed:\n{_COLOR_HINT}\n\n"
        f"Return JSON following this schema:\n{_EDIT_SCHEMA}"
    )
    resp = client.chat.completions.create(
        model=model,
        temperature=0.2,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": sys_msg},
            {"role": "user", "content": user_msg},
        ],
    )
    return json.loads(resp.choices[0].message.content)

def _deep_merge_set(dst: dict, patch: dict):
    for k, v in patch.items():
        if isinstance(v, dict) and isinstance(dst.get(k), dict):
            _deep_merge_set(dst[k], v)
        else:
            dst[k] = v

def apply_edits_to_analysis(analysis: dict, edits: dict) -> dict:
    objects = analysis.get("objects", [])
    for e in (edits.get("edits") or []):
        match = (e.get("object_match") or {})
        setter = (e.get("set") or {})
        if not setter:
            continue
        # ëŒ€ìƒ: id ìš°ì„ , ì—†ìœ¼ë©´ label
        target = None
        if match.get("id"):
            for o in objects:
                if o.get("id") == match["id"]:
                    target = o; break
        if target is None and match.get("label"):
            for o in objects:
                if (o.get("label") or "").lower() == match["label"].lower():
                    target = o; break
        if target is None:
            continue
        if "attributes" in setter and not isinstance(target.get("attributes"), dict):
            target["attributes"] = {}
        _deep_merge_set(target, setter)
    return analysis

def normalize_analysis_to_english(analysis: dict, api_key: str, model: str = "gpt-4o-mini") -> dict:
    """
    ì•ˆì „ë§: ë§Œì•½ í¸ì§‘ ê²°ê³¼ì— í•œêµ­ì–´ê°€ ì„ì—¬ë„ ì „ì²´ JSON ë‚´ ë¬¸ìì—´ì„ ì˜ì–´ë¡œ ì •ê·œí™”.
    í‚¤/ìˆ«ì/êµ¬ì¡°ëŠ” ë³€ê²½ ê¸ˆì§€.
    """
    client = OpenAI(api_key=api_key)
    sys_msg = (
        "You will receive a JSON. Return the same JSON but with ALL string values translated to ENGLISH ONLY. "
        "Do not change keys, structure, or any numeric values. Keep arrays and objects intact."
    )
    payload = json.dumps(analysis, ensure_ascii=False)
    resp = client.chat.completions.create(
        model=model,
        temperature=0.0,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": sys_msg},
            {"role": "user", "content": payload},
        ],
    )
    return json.loads(resp.choices[0].message.content)

def polish_english_prompt(en_prompt: str, api_key: str, model: str = "gpt-4o-mini") -> str:
    """
    EN í”„ë¡¬í”„íŠ¸ë¥¼ FLUX ì¹œí™”ì ìœ¼ë¡œ ë‹¤ë“¬ìŒ:
    - í•œ ë¬¸ë‹¨, 40~80 ë‹¨ì–´
    - ë¬¸ë²•/í‘œí˜„ ì–´ìƒ‰í•¨ ìˆ˜ì • (e.g., 'a illustration'â†’'an illustration', 'in the left'â†’'on the left')
    - ê°ì²´/ìƒ‰/ìœ„ì¹˜/êµ¬ë„/ìŠ¤íƒ€ì¼/í’ˆì§ˆ ì •ë³´ëŠ” ì¶”ê°€/ì‚­ì œí•˜ì§€ ì•ŠìŒ
    - ì½œë¡ /ë¦¬ìŠ¤íŠ¸/ë”°ì˜´í‘œ/ì½”ë“œë¸”ë¡ ê¸ˆì§€
    """
    client = OpenAI(api_key=api_key)
    sys_msg = (
        "You are a careful prompt editor for FLUX image generation. "
        "Rewrite the given English prompt into one fluent paragraph (about 40â€“80 words). "
        "Fix grammar and awkward phrasing; prefer 'on the left/right' not 'in the left/right'; "
        "use 'an illustration' not 'a illustration'. "
        "Keep ALL entities, colors, spatial relations, composition, and style descriptors; "
        "do NOT add or remove facts. No lists, no colons, no quotes, no code blocks."
    )
    resp = client.chat.completions.create(
        model=model, temperature=0.2,
        messages=[{"role": "system", "content": sys_msg},
                  {"role": "user", "content": en_prompt}]
    )
    return resp.choices[0].message.content.strip().replace("```", "").strip()

# def english_to_korean_prompt(en_prompt: str, api_key: str, model: str = "gpt-4o-mini") -> str:
#     """
#     ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜(ì½œë¡ /ë¦¬ìŠ¤íŠ¸ ê¸ˆì§€, 2~4ë¬¸ì¥).
#     """
#     client = OpenAI(api_key=api_key)
#     sys_msg = (
#         "You are a professional Korean copywriter for children's picture-book prompts. "
#         "Rewrite the given English prompt into fluent Korean natural sentences for an image generation model. "
#         "Keep spatial relations and composition details. No colons, bullets, or code blocks. 2â€“4 sentences."
#     )
#     resp = client.chat.completions.create(
#         model=model, temperature=0.2,
#         messages=[{"role": "system", "content": sys_msg},
#                   {"role": "user", "content": en_prompt}]
#     )
#     return resp.choices[0].message.content.strip().replace("```", "").strip()

# ğŸ”§ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (ì§ˆë¬¸ì—ì„œ ì£¼ì‹  ê·¸ëŒ€ë¡œ)
def generate_image(prompt, idx):
    try:
        print(f"ğŸ¨ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘: {prompt[:50]}...")

        flux_api = os.environ.get("BFL_API_KEY")
        finetune_id = os.environ.get("BFL_FINETUNE_ID")

        response = finetune_inference(
            finetune_id=finetune_id,
            api_key=flux_api,
            endpoint="flux-pro-1.1-ultra-finetuned",
            prompt=prompt,
            width=1024,
            height=768,
        )

        request_id = response.get("id")
        if not request_id:
            print("âŒ ìš”ì²­ IDë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None

        # ìƒíƒœ í™•ì¸ ë£¨í”„
        for attempt in range(60):
            time.sleep(0.5)
            result = get_inference(id=request_id, api_key=flux_api)
            status = result.get("status")

            if status == "Ready":
                image_url = result["result"]["sample"]
                print(f"âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ! URL: {image_url}")

                image_response = requests.get(image_url)
                image = Image.open(BytesIO(image_response.content))

                os.makedirs("fairy_tale_pictures", exist_ok=True)
                image_path = f"fairy_tale_pictures/image_{idx}.png"
                image.save(image_path)

                print(f"ğŸ‰ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {image_path}")
                return image_path

            elif status == "Request Moderated":
                print("ğŸš¨ ìš”ì²­ì´ ì½˜í…ì¸  í•„í„°ë§ì— ì˜í•´ ì°¨ë‹¨ë¨.")
                return None
            elif status == "Failed":
                print("âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨.")
                return None

        print("â³ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ë„ë‹¬")
        return None

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# =========================
# ì¸í„°ë™í‹°ë¸Œ ì‹¤í–‰(ë‹¨ì¼ ì´ë¯¸ì§€)
# =========================
def interactive_session(api_key: str, image_path: str, out_dir="analysis_results",
                        vision_model="gpt-4o-mini", lang_model="gpt-4o-mini", edit_model="gpt-4o-mini",
                        show_en=False):
    ensure_dir(out_dir)
    stem = os.path.splitext(os.path.basename(image_path))[0]

    # 1) ë¶„ì„
    image_ref = load_image_as_data_url(image_path)
    analysis = call_gpt_vision(image_ref=image_ref, api_key=api_key, model=vision_model)

    # ë³´ì •: ëˆ„ë½ ìƒ‰ìƒ ë°±ì—…
    fallback_hex = approx_dominant_hex(image_path)
    if isinstance(analysis, dict) and "objects" in analysis and isinstance(analysis["objects"], list):
        for obj in analysis["objects"]:
            hexv = obj.get("dominant_color_hex")
            if not (isinstance(hexv, str) and hexv.startswith("#") and len(hexv) == 7):
                if fallback_hex:
                    obj["dominant_color_hex"] = fallback_hex

    # ì €ì¥(ì›ë³¸ v1, ì˜ì–´ ìƒíƒœ)
    v = 1
    path_json_v = os.path.join(out_dir, f"{stem}_analysis_v{v}.json")
    save_json(analysis, path_json_v)

    # 2) ì›ë³¸ í”„ë¡¬í”„íŠ¸
    en = build_english_prompt(analysis)
    en_polished = polish_english_prompt(en, api_key=api_key, model=lang_model)

    if show_en:
        print(f"\n=== [{os.path.basename(image_path)}] EN prompt (original, polished) ===")
        print(en_polished); print("="*60)

    ko = english_to_korean_prompt_strict(en_polished, api_key=api_key, model=lang_model)
    print(f"\n=== [{os.path.basename(image_path)}] í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ (ì›ë³¸) ===")
    print(ko); print("="*60 + "\n")


    # 3) ì¸í„°ë™í‹°ë¸Œ í¸ì§‘ ë£¨í”„
    print("ìˆ˜ì • ì§€ì‹œë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆ) ê°•ì•„ì§€ëŠ” í°ìƒ‰ìœ¼ë¡œ ë°”ê¿”ì¤˜.  (ê·¸ë§Œí•˜ë ¤ë©´ ì—”í„° ë˜ëŠ” 'q')")
    current = analysis
    while True:
        try:
            instr = input("> ")
        except KeyboardInterrupt:
            print("\nì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not instr or instr.strip().lower() in ("q", "quit", "exit"):
            print("í¸ì§‘ ì„¸ì…˜ ì¢…ë£Œ.")
            break

        # 3-1) í¸ì§‘ì•ˆ ìƒì„±(í•œê¸€â†’ì˜ì–´ edits) â†’ ì ìš©
        try:
            edits = propose_edits_via_gpt(current, instr.strip(), api_key=api_key, model=edit_model)
            current = apply_edits_to_analysis(current, edits)
            # 3-1.5) ì˜ì–´ ì •ê·œí™”(í˜¹ì‹œ í•œêµ­ì–´ê°€ ì„ì˜€ì„ ê²½ìš° ëŒ€ë¹„)
            current = normalize_analysis_to_english(current, api_key=api_key, model=edit_model)
        except Exception as e:
            print(f"[ê²½ê³ ] í¸ì§‘ ì ìš© ì¤‘ ì˜¤ë¥˜: {e}")
            continue

        # 3-2) ë²„ì „ ì—… ì €ì¥(ì˜ì–´ JSON ë³´ì¥)
        v += 1
        path_json_v = os.path.join(out_dir, f"{stem}_analysis_v{v}.json")
        save_json(current, path_json_v)
        print(f"[ì €ì¥] Updated object JSON (EN) â†’ {path_json_v}")

        # 3-3) ìˆ˜ì •ë³¸: EN â†’ Polish â†’ KO (ë¨¼ì € ì¶œë ¥) â†’ ì´ë¯¸ì§€ ìƒì„±
        en2 = build_english_prompt(current)
        en2_polished = polish_english_prompt(en2, api_key=api_key, model=lang_model)

        print("\n=== English Prompt (edited, polished) ===")
        print(en2_polished)
        print("=" * 60)

        ko2 = english_to_korean_prompt_strict(en2_polished, api_key=api_key, model=lang_model)
        print("\n=== í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ (ìˆ˜ì •ë³¸) ===")
        print(ko2)
        print("=" * 60 + "\n")

        # ê·¸ ë‹¤ìŒ ì´ë¯¸ì§€ ìƒì„±
        generate_image(en2_polished, v)


        print("ì¶”ê°€ ìˆ˜ì • ì§€ì‹œë¬¸ì„ ê³„ì† ì…ë ¥í•˜ê±°ë‚˜, ì—”í„°ë¡œ ì¢…ë£Œí•˜ì„¸ìš”.")


# =========================
# ë°°ì¹˜ ì²˜ë¦¬(ì—¬ëŸ¬ ì´ë¯¸ì§€)
# =========================
def interactive_session_batch(api_key: str, image_paths: list, out_dir="analysis_results",
                              vision_model="gpt-4o-mini", lang_model="gpt-4o-mini", edit_model="gpt-4o-mini",
                              show_en=False, pause_between=True):
    for idx, path in enumerate(image_paths, 1):
        print(f"\n>>> [{idx}/{len(image_paths)}] ìë™ ì„ íƒëœ ì´ë¯¸ì§€: {os.path.basename(path)}")
        interactive_session(api_key, path, out_dir, vision_model, lang_model, edit_model, show_en=show_en)
        if pause_between and idx < len(image_paths):
            print("\në‹¤ìŒ ì´ë¯¸ì§€ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤...\n")

# =========================
# ë©”ì¸
# =========================
def main():
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    parser = argparse.ArgumentParser(description="Auto-pick from reference_image, interactive KO edits â†’ EN JSON versioning â†’ EN prompt â†’ KO prompt.")
    parser.add_argument("--image", help="íŠ¹ì • íŒŒì¼ë§Œ ì²˜ë¦¬ (reference_image/ ì•ˆì˜ íŒŒì¼ëª…)")
    parser.add_argument("--all", action="store_true", help="í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ìˆœì°¨ ì²˜ë¦¬")
    parser.add_argument("--pick", choices=["newest", "oldest", "alpha"], default="newest", help="ìë™ ì„ íƒ ê¸°ì¤€")
    parser.add_argument("--out-dir", default="analysis_results")
    parser.add_argument("--vision-model", default="gpt-4o-mini")
    parser.add_argument("--lang-model", default="gpt-4o-mini")
    parser.add_argument("--edit-model", default="gpt-4o-mini")
    parser.add_argument("--show-en", action="store_true", help="EN promptë„ í•¨ê»˜ ì¶œë ¥")
    args = parser.parse_args()

    base_dir = os.path.dirname(os.path.abspath(__file__))
    ref_dir = os.path.join(base_dir, "reference_image")

    items = list_reference_images(ref_dir)
    if args.image:
        target_path = os.path.join(ref_dir, args.image)
        if not os.path.exists(target_path):
            raise FileNotFoundError(f"reference_image/{args.image} ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        image_paths = [target_path]
        print(f"ì§€ì •ëœ ì´ë¯¸ì§€ 1ì¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤: {args.image}")
    else:
        if not items:
            raise FileNotFoundError("reference_image í´ë”ì— ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        items_sorted = sort_images(items, args.pick)
        if args.all:
            image_paths = [p for (p, n, t) in items_sorted]
            names = ", ".join(os.path.basename(p) for p in image_paths)
            print(f"reference_imageì—ì„œ {len(image_paths)}ì¥ ìë™ ì„ íƒ: {names}")
        else:
            image_paths = [items_sorted[0][0]]
            print(f"reference_imageì—ì„œ ìë™ ì„ íƒ(ê¸°ì¤€: {args.pick}): {os.path.basename(image_paths[0])}")

    if len(image_paths) == 1:
        interactive_session(
            api_key=api_key,
            image_path=image_paths[0],
            out_dir=args.out_dir,
            vision_model=args.vision_model,
            lang_model=args.lang_model,
            edit_model=args.edit_model,
            show_en=args.show_en,
        )
    else:
        interactive_session_batch(
            api_key=api_key,
            image_paths=image_paths,
            out_dir=args.out_dir,
            vision_model=args.vision_model,
            lang_model=args.lang_model,
            edit_model=args.edit_model,
            show_en=args.show_en,
        )

if __name__ == "__main__":
    main()
